{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\", split=[\"train[:85%]\", \"train[85%:]\"], as_supervised=True\n",
    ")\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "NUM_IMAGES = 1000\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for (image, label) in train_ds.take(NUM_IMAGES):\n",
    "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    images.append(image.numpy())\n",
    "    labels.append(label.numpy())\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_model = tf.keras.models.load_model(\"my_model\")\n",
    "bit_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        tf.keras.layers.Rescaling(scale=1.0 / 255),\n",
    "        bit_model.layers[1],\n",
    "        tf.keras.layers.Normalization(mean=0, variance=1),\n",
    "    ],\n",
    "    name=\"embedding_model\",\n",
    ")\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_func(embedding, random_vectors):\n",
    "    embedding = np.array(embedding)\n",
    "\n",
    "    # Random projection.\n",
    "    bools = np.dot(embedding, random_vectors) > 0\n",
    "    return [bool2int(bool_vec) for bool_vec in bools]\n",
    "\n",
    "\n",
    "def bool2int(x):\n",
    "    y = 0\n",
    "    for i, j in enumerate(x):\n",
    "        if j:\n",
    "            y += 1 << i\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "    def __init__(self, hash_size, dim):\n",
    "        self.table = {}\n",
    "        self.hash_size = hash_size\n",
    "        self.random_vectors = np.random.randn(hash_size, dim).T\n",
    "\n",
    "    def add(self, id, vectors, label):\n",
    "        # Create a unique indentifier.\n",
    "        entry = {\"id_label\": str(id) + \"_\" + str(label)}\n",
    "\n",
    "        # Compute the hash values.\n",
    "        hashes = hash_func(vectors, self.random_vectors)\n",
    "\n",
    "        # Add the hash values to the current table.\n",
    "        for h in hashes:\n",
    "            if h in self.table:\n",
    "                self.table[h].append(entry)\n",
    "            else:\n",
    "                self.table[h] = [entry]\n",
    "\n",
    "    def query(self, vectors):\n",
    "        # Compute hash value for the query vector.\n",
    "        hashes = hash_func(vectors, self.random_vectors)\n",
    "        results = []\n",
    "\n",
    "        # Loop over the query hashes and determine if they exist in\n",
    "        # the current table.\n",
    "        for h in hashes:\n",
    "            if h in self.table:\n",
    "                results.extend(self.table[h])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, hash_size, dim, num_tables):\n",
    "        self.num_tables = num_tables\n",
    "        self.tables = []\n",
    "        for i in range(self.num_tables):\n",
    "            self.tables.append(Table(hash_size, dim))\n",
    "\n",
    "    def add(self, id, vectors, label):\n",
    "        for table in self.tables:\n",
    "            table.add(id, vectors, label)\n",
    "\n",
    "    def query(self, vectors):\n",
    "        results = []\n",
    "        for table in self.tables:\n",
    "            results.extend(table.query(vectors))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildLSHTable:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prediction_model,\n",
    "        concrete_function=False,\n",
    "        hash_size=8,\n",
    "        dim=2048,\n",
    "        num_tables=10,\n",
    "    ):\n",
    "        self.hash_size = hash_size\n",
    "        self.dim = dim\n",
    "        self.num_tables = num_tables\n",
    "        self.lsh = LSH(self.hash_size, self.dim, self.num_tables)\n",
    "\n",
    "        self.prediction_model = prediction_model\n",
    "        self.concrete_function = concrete_function\n",
    "\n",
    "    def train(self, training_files):\n",
    "        for id, training_file in enumerate(training_files):\n",
    "            # Unpack the data.\n",
    "            image, label = training_file\n",
    "            if len(image.shape) < 4:\n",
    "                image = image[None, ...]\n",
    "\n",
    "            # Compute embeddings and update the LSH tables.\n",
    "            # More on `self.concrete_function()` later.\n",
    "            if self.concrete_function:\n",
    "                features = self.prediction_model(tf.constant(image))[\n",
    "                    \"normalization\"\n",
    "                ].numpy()\n",
    "            else:\n",
    "                features = self.prediction_model.predict(image)\n",
    "            self.lsh.add(id, features, label)\n",
    "\n",
    "    def query(self, image, verbose=True):\n",
    "        # Compute the embeddings of the query image and fetch the results.\n",
    "        if len(image.shape) < 4:\n",
    "            image = image[None, ...]\n",
    "\n",
    "        if self.concrete_function:\n",
    "            features = self.prediction_model(tf.constant(image))[\n",
    "                \"normalization\"\n",
    "            ].numpy()\n",
    "        else:\n",
    "            features = self.prediction_model.predict(image)\n",
    "\n",
    "        results = self.lsh.query(features)\n",
    "        if verbose:\n",
    "            print(\"Matches:\", len(results))\n",
    "\n",
    "        # Calculate Jaccard index to quantify the similarity.\n",
    "        counts = {}\n",
    "        for r in results:\n",
    "            if r[\"id_label\"] in counts:\n",
    "                counts[r[\"id_label\"]] += 1\n",
    "            else:\n",
    "                counts[r[\"id_label\"]] = 1\n",
    "        for k in counts:\n",
    "            counts[k] = float(counts[k]) / self.dim\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup():\n",
    "    dummy_sample = tf.ones((1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    for _ in range(100):\n",
    "        _ = embedding_model.predict(dummy_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup()\n",
    "\n",
    "training_files = zip(images, labels)\n",
    "lsh_builder = BuildLSHTable(embedding_model)\n",
    "lsh_builder.train(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First serialize the embedding model as a SavedModel.\n",
    "embedding_model.save(\"embedding_model\")\n",
    "\n",
    "# Initialize the conversion parameters.\n",
    "params = tf.experimental.tensorrt.ConversionParams(\n",
    "    precision_mode=\"FP16\", maximum_cached_engines=16\n",
    ")\n",
    "\n",
    "# Run the conversion.\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir=\"embedding_model\", conversion_params=params\n",
    ")\n",
    "converter.convert()\n",
    "converter.save(\"tensorrt_embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tf.saved_model.load(\"tensorrt_embedding_model\")\n",
    "trt_model_function = root.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup()\n",
    "\n",
    "training_files = zip(images, labels)\n",
    "lsh_builder_trt = BuildLSHTable(trt_model_function, concrete_function=True)\n",
    "lsh_builder_trt.train(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for hash, entry in lsh_builder_trt.lsh.tables[0].table.items():\n",
    "    if idx == 5:\n",
    "        break\n",
    "    if len(entry) < 5:\n",
    "        print(hash, entry)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for image, label in validation_ds.take(100):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    validation_images.append(image.numpy())\n",
    "    validation_labels.append(label.numpy())\n",
    "\n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)\n",
    "validation_images.shape, validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 5\n",
    "    for (i, image) in enumerate(images):\n",
    "        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Query Image\\n\" + \"Label: {}\".format(labels[i]))\n",
    "        else:\n",
    "            ax.set_title(\"Similar Image # \" + str(i) + \"\\nLabel: {}\".format(labels[i]))\n",
    "        plt.imshow(image.astype(\"int\"))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def visualize_lsh(lsh_class):\n",
    "    idx = np.random.choice(len(validation_images))\n",
    "    image = validation_images[idx]\n",
    "    label = validation_labels[idx]\n",
    "    results = lsh_class.query(image)\n",
    "\n",
    "    candidates = []\n",
    "    labels = []\n",
    "    overlaps = []\n",
    "\n",
    "    for idx, r in enumerate(sorted(results, key=results.get, reverse=True)):\n",
    "        if idx == 4:\n",
    "            break\n",
    "        image_id, label = r.split(\"_\")[0], r.split(\"_\")[1]\n",
    "        candidates.append(images[int(image_id)])\n",
    "        labels.append(label)\n",
    "        overlaps.append(results[r])\n",
    "\n",
    "    candidates.insert(0, image)\n",
    "    labels.insert(0, label)\n",
    "\n",
    "    plot_images(candidates, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    visualize_lsh(lsh_builder)\n",
    "\n",
    "visualize_lsh(lsh_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    visualize_lsh(lsh_builder_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(lsh_class):\n",
    "    warmup()\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(1000):\n",
    "        image = np.ones((1, 224, 224, 3)).astype(\"float32\")\n",
    "        _ = lsh_class.query(image, verbose=False)\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Time taken: {end_time:.3f}\")\n",
    "\n",
    "\n",
    "benchmark(lsh_builder)\n",
    "\n",
    "benchmark(lsh_builder_trt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
