{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import squeezenet1_1, resnet18\n",
    "from torchvision.models.squeezenet import SqueezeNet1_1_Weights\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDmodel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MIDmodel2, self).__init__()\n",
    "        self.pretrained = resnet18(weights = ResNet18_Weights.DEFAULT)\n",
    "        # remove the last fully connected layer\n",
    "        self.pretrained.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(512, 4)\n",
    "\n",
    "    def get_embeddings(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, patients_ids, patients_df, transform=None):\n",
    "        self.patients_df = patients_df[patients_df[\"patient_id\"].isin(patients_ids)]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patients_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.patients_df.iloc[idx]\n",
    "        path = os.path.join(self.root_dir, row[\"patient_id\"] + \"_\" + row[\"exam_id\"] + \"_\" + row[\"spot\"] + \"_\" + row[\"frame_number\"] + \"_\" + row[\"score\"] + \".png\")\n",
    "        image = Image.open(path)\n",
    "        label = row[\"score\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = transforms.Resize((224, 224))(image)\n",
    "        image = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "\n",
    "        return image, int(label), path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDbinary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MIDbinary, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, preds):\n",
    "        self.preds = preds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.preds.iloc[idx][\"correct\"]\n",
    "        sms = self.preds.iloc[idx][[\"sm0\", \"sm1\", \"sm2\", \"sm3\"]]\n",
    "        sms = torch.tensor(list(sms.values), dtype=torch.float32)\n",
    "        return sms, int(label), self.preds.iloc[idx][\"path\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO TEST\n",
    "\n",
    "Resnet cm\n",
    "\n",
    "Binary cm\n",
    "\n",
    "t-SNE behaviour cm\n",
    "\n",
    "final cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"images/\"\n",
    "images_paths = glob.glob(f\"{data_dir}*.png\", recursive=True)\n",
    "images_df = pd.DataFrame([path[len(data_dir):-4].split(\"_\") for path in images_paths], columns=[\"patient_id\", \"exam_id\", \"spot\", \"frame_number\", \"score\"])\n",
    "images_df[\"score\"] = images_df[\"score\"].astype(str)\n",
    "images_df[\"frame_number\"] = images_df[\"frame_number\"].astype(str)\n",
    "images_df[\"spot\"] = images_df[\"spot\"].astype(str)\n",
    "images_df[\"patient_id\"] = images_df[\"patient_id\"].astype(str)\n",
    "images_df[\"exam_id\"] = images_df[\"exam_id\"].astype(str)\n",
    "patients_ids = set(images_df[\"patient_id\"])\n",
    "patients_ids = list(patients_ids)\n",
    "\n",
    "# select the 8 patients for training based on the most balanced distribution of the scores\n",
    "combs = list(itertools.combinations(patients_ids, 8))\n",
    "stds = []\n",
    "for i, c in enumerate(combs):\n",
    "    stds.append((images_df[images_df[\"patient_id\"].isin(c)].groupby(\"score\").count()[\"patient_id\"].std(), i))\n",
    "# sort the stds\n",
    "train_patients = [x for x in combs[min(stds)[1]]]\n",
    "print(train_patients)\n",
    "print(images_df[images_df[\"patient_id\"].isin(train_patients)].groupby(\"score\").count()[\"patient_id\"])\n",
    "test_patients = [x for x in patients_ids if x not in train_patients]\n",
    "print(test_patients)\n",
    "print(images_df[images_df[\"patient_id\"].isin(test_patients)].groupby(\"score\").count()[\"patient_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in test_patients:\n",
    "    # print the number of images for each score based on image_df\n",
    "    print(\"Number of images for each score for patient\", patient)\n",
    "    result = images_df[images_df[\"patient_id\"] == patient][\"score\"].value_counts()\n",
    "    # sort the result by score\n",
    "    result = result.sort_index()\n",
    "    print(result)\n",
    "\n",
    "max_number = 29\n",
    "selected_df_test = pd.DataFrame()\n",
    "for patient in test_patients:\n",
    "    for score in range(0,4):\n",
    "        # get the images for the patient and score\n",
    "        patient_score_df = images_df[(images_df[\"patient_id\"] == patient) & (images_df[\"score\"] == f\"{score}\")]\n",
    "        # if the number of images is less than 40, select all of them\n",
    "        if len(patient_score_df) < max_number:\n",
    "            selected_df_test = pd.concat([selected_df_test, patient_score_df])\n",
    "        else:\n",
    "            # select 29 images randomly\n",
    "            selected_df_test = pd.concat([selected_df_test, patient_score_df.sample(n=max_number, random_state=42)])\n",
    "print(len(selected_df_test))\n",
    "# print the number of images for each score based on selected_df\n",
    "print(\"Number of images for each score for the selected images\")\n",
    "result = selected_df_test[\"score\"].value_counts()\n",
    "# sort the result by score\n",
    "result = result.sort_index()\n",
    "print(result)\n",
    "\n",
    "# create a new dataframe using each entry of the selected_df as path\n",
    "paths_test_df = pd.DataFrame()\n",
    "for index, row in selected_df_test.iterrows():\n",
    "    # get the path\n",
    "    path = os.path.join(\"images/\", row[\"patient_id\"] + \"_\" + row[\"exam_id\"] + \"_\" + row[\"spot\"] + \"_\" + row[\"frame_number\"] + \"_\" + row[\"score\"] + \".png\" )\n",
    "    # create a new dataframe with the path\n",
    "    tmp_df = pd.DataFrame({\"path\": [path]})\n",
    "    # add the new dataframe to the values dataframe\n",
    "    paths_test_df = pd.concat([paths_test_df, tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(row):\n",
    "    return os.path.join(\"images/\", row[\"patient_id\"] + \"_\" + row[\"exam_id\"] + \"_\" + row[\"spot\"] + \"_\" + row[\"frame_number\"] + \"_\" + row[\"score\"] + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_tmp = images_df[images_df[\"patient_id\"].isin(test_patients)]\n",
    "test_images_df = test_images_tmp.reset_index(drop=True)\n",
    "test_images_df[\"path\"] = test_images_df.apply(getPath, axis=1)\n",
    "test_images_df = test_images_df[test_images_df[\"path\"].isin(paths_test_df[\"path\"])]\n",
    "test_dataset = ImageDataset(data_dir, test_patients, test_images_df)\n",
    "\n",
    "values_train = pd.read_csv(\"data/values_train.csv\") # to build t-SNE\n",
    "values_test = pd.read_csv(\"data/values_test.csv\")\n",
    "values_test = values_test[values_test[\"path\"].isin(paths_test_df[\"path\"])]\n",
    "values_test = values_test.drop(values_test[values_test[\"correct\"] == 1].sample(n=48, random_state=42).index)\n",
    "values_test = values_test.drop(columns=[\"path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of the models/MIDmodel2.pt\n",
    "model = MIDmodel2()\n",
    "model.load_state_dict(torch.load(\"models/MIDmodel2.pt\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "test_dataset = ImageDataset(data_dir, test_patients, test_images_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i, (image, label, path) in tqdm(enumerate(test_loader)):\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    y_true.append(label.item())\n",
    "    y_pred.append(predicted.item())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of the models/binary_model.pt\n",
    "model = MIDbinary()\n",
    "model.load_state_dict(torch.load(\"models/binary_model.pt\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "test_dataset = BinaryDataset(values_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i, (image, label, path) in tqdm(enumerate(test_loader)):\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    y_true.append(label.item())\n",
    "    y_pred.append(predicted.item())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of t-SNE\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for element in tqdm(values_test.iterrows()):\n",
    "    row = element[1].drop([\"true\", \"predicted\", \"correct\"])\n",
    "    values_test = pd.concat([values_test, row])\n",
    "    points = values_train[[\"sm0\", \"sm1\", \"sm2\", \"sm3\"]].values\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=400)\n",
    "    tsne_results = tsne.fit_transform(points)\n",
    "    distances = np.linalg.norm(tsne_results - tsne_results[len(tsne_results)-1], axis=1)\n",
    "    points_num = 12\n",
    "    nearest_points = np.argsort(distances)[:points_num]\n",
    "    nearest_points = np.delete(nearest_points, 0)\n",
    "    scores = []\n",
    "    for k in range(len(nearest_points)):\n",
    "        scores.append(values_train.iloc[nearest_points[k]][\"true\"])\n",
    "    mode_val = max(set(scores), key=scores.count)\n",
    "    y_true.append(element[\"true\"])\n",
    "    y_pred.append(mode_val)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
